{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.integrate import odeint\n",
    "import networkx as nx\n",
    "\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "\n",
    "pyro.set_rng_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create generic discrete probability function\n",
    "class cg_node():\n",
    "    def __init__(self,n_inputs,name):\n",
    "        \n",
    "        self.n_inputs = n_inputs\n",
    "        self.name = name\n",
    "        \n",
    "        if n_inputs == 0:\n",
    "            self.label = 'exogenous'\n",
    "        else:\n",
    "            self.label = 'endogenous'\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def p_init(self,input_data,var_data):\n",
    "        \n",
    "        self.n_data = len(input_data)\n",
    "        \n",
    "        self.input_data = input_data\n",
    "        self.var_data = var_data\n",
    "        \n",
    "        if self.n_inputs == 0:\n",
    "            p_ave = np.zeros(3)\n",
    "            n_count = self.n_data\n",
    "            for i in range(0,3):\n",
    "                p_ave[i] = np.sum(var_data == i-1)/n_count\n",
    "        \n",
    "        elif self.n_inputs == 1:\n",
    "            n_count = np.zeros(3)\n",
    "            p_ave = np.zeros((3,3))\n",
    "            \n",
    "            for i in range(0,3):\n",
    "                n_count[i] = np.sum(input_data == i-1)\n",
    "                for j in range(0,3):\n",
    "                    p_ave[j,i] = np.sum((input_data[:,0] == i-1)*(var_data == j-1))/n_count[i]\n",
    "            \n",
    "            \n",
    "        elif self.n_inputs == 2:\n",
    "            n_count = np.zeros((3,3))\n",
    "            p_ave = np.zeros((3,3,3))\n",
    "            \n",
    "            for i in range(0,3):\n",
    "                for j in range(0,3):\n",
    "                    n_count[i,j] = np.sum((input_data[:,0] == i-1)*(input_data[:,1] == j-1))\n",
    "                    for k in range(0,3):\n",
    "                        p_ave[k,i,j] = np.sum(\n",
    "                            (input_data[:,0] == i-1)*(input_data[:,1] == j-1)*(var_data == k-1))/n_count[i,j]\n",
    "                        \n",
    "        elif self.n_inputs == 3:\n",
    "            n_count = np.zeros((3,3,3))\n",
    "            p_ave = np.zeros((3,3,3,3))\n",
    "            \n",
    "            for i in range(0,3):\n",
    "                for j in range(0,3):\n",
    "                    for k in range(0,3):\n",
    "                        n_count[i,j,k] = np.sum(\n",
    "                            (input_data[:,0] == i-1)*(input_data[:,1] == j-1)*(input_data[:,2] == k-1))\n",
    "                        for m in range(0,3):\n",
    "                            p_ave[m,i,j,k] = np.sum((input_data[:,0] == i-1)*(input_data[:,1] == j-1)\n",
    "                                *(input_data[:,2] == k-1)*(var_data == m-1))/n_count[i,j,k]\n",
    "                            \n",
    "        elif self.n_inputs == 4:\n",
    "            n_count = np.zeros((3,3,3,3))\n",
    "            p_ave = np.zeros((3,3,3,3,3))\n",
    "            \n",
    "            for i in range(0,3):\n",
    "                for j in range(0,3):\n",
    "                    for k in range(0,3):\n",
    "                        for m in range(0,3):\n",
    "                            n_count[i,j,k,m] = np.sum((input_data[:,0] == i-1)*(input_data[:,1] == j-1)\n",
    "                                *(input_data[:,2] == k-1)*(input_data[:,3] == m-1))\n",
    "                            for q in range(0,3):\n",
    "                                p_ave[q,i,j,k,m] = np.sum((input_data[:,0] == i-1)*(input_data[:,1] == j-1)\n",
    "                                    *(input_data[:,2] == k-1)*(input_data[:,3] == m-1)\n",
    "                                    *(var_data == q-1))/n_count[i,j,k,m]\n",
    "                        \n",
    "            \n",
    "        else:\n",
    "            print('error -- too many inputs')\n",
    "            return\n",
    "            \n",
    "        self.n_count = torch.tensor(n_count/self.n_data)\n",
    "        self.prob_dist = torch.tensor(p_ave)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def sample(self,data_in=[]):\n",
    "        \n",
    "        if self.n_inputs == 0:\n",
    "            p_temp = self.prob_dist\n",
    "        elif self.n_inputs == 1:\n",
    "            p_temp = torch.squeeze(self.prob_dist[data_in[0]+1,:])\n",
    "        elif self.n_inputs == 2:\n",
    "            p_temp = torch.squeeze(self.prob_dist[data_in[0]+1,data_in[1]+1,:])\n",
    "        elif self.n_inputs == 3:\n",
    "            p_temp = torch.squeeze(self.prob_dist[data_in[0]+1,data_in[1]+1,data_in[2]+1,:])\n",
    "            \n",
    "        else:\n",
    "            print('error -- too many inputs')\n",
    "            p_temp = []\n",
    "        \n",
    "        return torch.squeeze(pyro.sample(self.name,pyro.distributions.Categorical(probs = p_temp)).int()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cg_graph():\n",
    "    \n",
    "    def __init__(self,str_list=[],bel_graph=[]):\n",
    "        \n",
    "        edge_list = []\n",
    "\n",
    "        entity_list = []\n",
    "        \n",
    "        if str_list:\n",
    "\n",
    "            for item in str_list:\n",
    "\n",
    "                sub_ind = item.find('=')\n",
    "\n",
    "                sub_temp = item[:sub_ind-1]\n",
    "                obj_temp = item[sub_ind+3:]\n",
    "                \n",
    "                rel_temp = item[sub_ind:sub_ind+2]\n",
    "\n",
    "                if sub_temp not in entity_list:\n",
    "                    entity_list.append(sub_temp)\n",
    "                if obj_temp not in entity_list:\n",
    "                    entity_list.append(obj_temp)\n",
    "\n",
    "                edge_list.append([sub_temp,obj_temp,rel_temp])\n",
    "                \n",
    "        elif bel_graph:\n",
    "            \n",
    "            for item in bel_graph.edges:\n",
    "                edge_temp = bel_graph.get_edge_data(item[0],item[1],item[2])\n",
    "                sub_temp = str(item[0])\n",
    "                obj_temp = str(item[1])\n",
    "                rel_temp = edge_temp['relation']\n",
    "                \n",
    "                if sub_temp not in entity_list:\n",
    "                    entity_list.append(sub_temp)\n",
    "                if obj_temp not in entity_list:\n",
    "                    entity_list.append(obj_temp)\n",
    "                \n",
    "                edge_list.append([sub_temp,obj_temp,rel_temp])\n",
    "\n",
    "        n_nodes = len(entity_list)\n",
    "        self.n_nodes = n_nodes\n",
    "\n",
    "        adj_mat = np.zeros((n_nodes,n_nodes),dtype=int)\n",
    "\n",
    "        for item in edge_list:\n",
    "            out_ind = entity_list.index(item[0])\n",
    "            in_ind = entity_list.index(item[1])\n",
    "            adj_mat[out_ind,in_ind] = 1\n",
    "            \n",
    "        self.edge_list = edge_list\n",
    "        self.entity_list = entity_list\n",
    "        \n",
    "        #self.graph = nx.DiGraph(adj_mat)\n",
    "        \n",
    "        node_dict = {}\n",
    "        \n",
    "        for i in range(0,n_nodes):\n",
    "            node_dict[entity_list[i]] = cg_node(np.sum(adj_mat[:,i]),entity_list[i])\n",
    "        \n",
    "        self.node_dict = node_dict\n",
    "        \n",
    "        #self.parent_ind_list = []\n",
    "        #self.child_ind_list = []\n",
    "        self.parent_name_dict = {}\n",
    "        #self.child_name_dict = {}\n",
    "        \n",
    "        self.parent_ind_list = [np.where(adj_mat[:,i] > 0)[0] for i in range(0,n_nodes)]\n",
    "        #self.child_ind_list = [np.where(self.adj_mat[i,:] > 0)[0] for i in range(0,n_nodes)]\n",
    "        \n",
    "        for i in range(0,n_nodes):\n",
    "            self.parent_name_dict[entity_list[i]] = [entity_list[item] for item in self.parent_ind_list[i]]\n",
    "            #self.child_name_dict[entity_list[i]] = [entity_list[item] for item in self.child_ind_list[i]]\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def prob_init(self,data_in):\n",
    "        # initialize all of the nodes\n",
    "        \n",
    "        exog_list = []\n",
    "        prob_dict = {}\n",
    "        \n",
    "        for name in self.node_dict:\n",
    "            i = self.entity_list.index(name)\n",
    "            data_in_temp = data_in[:,self.parent_ind_list[i]]\n",
    "            data_out_temp = data_in[:,i]\n",
    "            \n",
    "            self.node_dict[name].p_init(data_in_temp,data_out_temp)\n",
    "            \n",
    "            if self.node_dict[name].n_inputs == 0:\n",
    "                exog_list.append(name)\n",
    "            prob_dict[name] = self.node_dict[name].prob_dist\n",
    "        \n",
    "        self.exog_list = exog_list\n",
    "        self.prob_dict = prob_dict\n",
    "\n",
    "        return\n",
    "        \n",
    "    def model_sample(self):\n",
    "        \n",
    "        # define exogenous samples\n",
    "        \n",
    "        sample_dict = {}\n",
    "        \n",
    "        for item in self.exog_list:\n",
    "            sample_dict[item] = self.node_dict[item].sample()\n",
    "            \n",
    "        flag = 0\n",
    "        while flag == 0:\n",
    "            \n",
    "            # find all nodes not in sample_dict with parents entirely in sample dict and sample those nodes\n",
    "            for item in self.entity_list:\n",
    "                if (item not in sample_dict \n",
    "                    and np.all([item2 in sample_dict for item2 in self.parent_name_dict[item]])):\n",
    "                    \n",
    "                    sample_dict[item] = self.node_dict[item].sample(\n",
    "                        [sample_dict[item2] for item2 in self.parent_name_dict[item]])\n",
    "            \n",
    "            # if sample dict has all of the nodes in entity list, stop\n",
    "            if sorted([item for item in sample_dict]) == sorted(self.entity_list):\n",
    "                flag = 1\n",
    "            \n",
    "        \n",
    "        return sample_dict\n",
    "    \n",
    "    def model_cond_sample(self,data_dict):\n",
    "        \n",
    "        data_in = {}\n",
    "        for item in data_dict:\n",
    "            data_in[item] = data_dict[item] + 1\n",
    "        \n",
    "        cond_model = pyro.condition(self.model_sample,data=data_in)\n",
    "        return cond_model()\n",
    "        \n",
    "    def model_do_sample(self,do_dict):\n",
    "        \n",
    "        data_in = {}\n",
    "        for item in do_dict:\n",
    "            data_in[item] = do_dict[item] + 1\n",
    "        \n",
    "        do_model = pyro.do(self.model_sample,data=data_in)\n",
    "        return do_model()\n",
    "    \n",
    "    def model_do_cond_sample(self,do_dict,data_dict):\n",
    "        \n",
    "        if np.any([[item1 == item2 for item1 in do_dict] for item2 in data_dict]):\n",
    "            print('overlapping lists!')\n",
    "            return\n",
    "        else:\n",
    "            do_dict_in = {}\n",
    "            for item in do_dict:\n",
    "                do_dict_in[item] = do_dict[item] + 1\n",
    "                \n",
    "            data_dict_in = {}\n",
    "            for item in data_dict:\n",
    "                data_dict_in[item] = data_dict[item] + 1\n",
    "            \n",
    "            do_model = pyro.do(self.model_sample,data=do_dict_in)\n",
    "            cond_model = pyro.condition(do_model,data=data_dict_in)\n",
    "            return cond_model()\n",
    "    \n",
    "    def model_counterfact(self,obs_dict,do_dict_counter):\n",
    "        # find conditional distribution on exogenous variables given observations and do variable values\n",
    "        cond_dict = self.model_cond_sample(obs_dict)\n",
    "        cond_dict_temp = {}\n",
    "        for item in self.exog_list:\n",
    "            cond_dict_temp[item] = cond_dict[item]\n",
    "        \n",
    "        # evaluate observed variables given this condition distribution and do_dict_counter do-variables\n",
    "        return self.model_do_cond_sample(do_dict_counter,cond_dict_temp)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_list = ['temp =| cloudy','cloudy => rainy','temp => icream','rainy =| icream']\n",
    "graph_test = cg_graph(str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp', 0]\n",
      "['cloudy', 1]\n",
      "['rainy', 1]\n",
      "['icream', 2]\n"
     ]
    }
   ],
   "source": [
    "for item in graph_test.node_dict:\n",
    "    print([graph_test.node_dict[item].name,graph_test.node_dict[item].n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp']\n"
     ]
    }
   ],
   "source": [
    "graph_test.prob_init(tot_data)\n",
    "print(graph_test.exog_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for item in graph_test.node_dict:\n",
    "    print(item)\n",
    "    print(graph_test.node_dict[item].n_count)\n",
    "    print(graph_test.node_dict[item].prob_dist)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cloudy': tensor(-1, dtype=torch.int32),\n",
       " 'icream': tensor(0, dtype=torch.int32),\n",
       " 'rainy': tensor(-1, dtype=torch.int32),\n",
       " 'temp': tensor(1, dtype=torch.int32)}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_test.model_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp\n",
      "tensor(-1, dtype=torch.int32)\n",
      "\n",
      "cloudy\n",
      "tensor(-1, dtype=torch.int32)\n",
      "\n",
      "rainy\n",
      "tensor(1, dtype=torch.int32)\n",
      "\n",
      "icream\n",
      "tensor(1, dtype=torch.int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cond_dict = {}\n",
    "cond_dict['cloudy'] = torch.Tensor([-1]).int()\n",
    "\n",
    "cond_test = graph_test.model_cond_sample(cond_dict)\n",
    "\n",
    "for item in cond_test:\n",
    "    print(item)\n",
    "    print(cond_test[item])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp\n",
      "tensor(0, dtype=torch.int32)\n",
      "\n",
      "cloudy\n",
      "tensor(1, dtype=torch.int32)\n",
      "\n",
      "rainy\n",
      "tensor(1, dtype=torch.int32)\n",
      "\n",
      "icream\n",
      "tensor(0, dtype=torch.int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "do_dict = {}\n",
    "do_dict['rainy'] = torch.Tensor([1]).int()\n",
    "\n",
    "do_test = graph_test.model_do_sample(do_dict)\n",
    "\n",
    "for item in do_test:\n",
    "    print(item)\n",
    "    print(do_test[item])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp\n",
      "tensor(0, dtype=torch.int32)\n",
      "\n",
      "cloudy\n",
      "tensor(-1, dtype=torch.int32)\n",
      "\n",
      "rainy\n",
      "tensor(1, dtype=torch.int32)\n",
      "\n",
      "icream\n",
      "tensor(1, dtype=torch.int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "do_cond_test = graph_test.model_do_cond_sample(do_dict,cond_dict)\n",
    "for item in do_cond_test:\n",
    "    print(item)\n",
    "    print(do_cond_test[item])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp\n",
      "tensor(-1, dtype=torch.int32)\n",
      "\n",
      "cloudy\n",
      "tensor(1, dtype=torch.int32)\n",
      "\n",
      "rainy\n",
      "tensor(0, dtype=torch.int32)\n",
      "\n",
      "icream\n",
      "tensor(1, dtype=torch.int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "obs_dict = {}\n",
    "obs_dict['icream'] = torch.Tensor([1]).int()\n",
    "obs_dict['rainy'] = torch.Tensor([-1]).int()\n",
    "\n",
    "do_dict = {}\n",
    "do_dict['rainy'] = torch.Tensor([0]).int()\n",
    "\n",
    "\n",
    "counter_test = graph_test.model_counterfact(obs_dict,do_dict)\n",
    "for item in counter_test:\n",
    "    print(item)\n",
    "    print(counter_test[item])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_test.calc_do_cond(['rainy'],do_dict,['temp'],['icream'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in graph_test.prob_dict:\n",
    "    print(item)\n",
    "    print(graph_test.prob_dict[item])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = pyro.sample('',pyro.distributions.Multinomial(probs = torch.Tensor([0.3,0.2,0.5]))).bool()\n",
    "#samp_out = pyro.sample('',pyro.distributions.Multinomial(probs = self.prob_dist))\n",
    "print(x)\n",
    "y = torch.Tensor([-1,0,1])[x]\n",
    "print(y)\n",
    "\n",
    "z = torch.Tensor([1]).int()\n",
    "print(z)\n",
    "print(z+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(graph_test.calc_prob(['icream']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(dir(graph_test))\n",
    "print()\n",
    "print(graph_test.entity_list)\n",
    "print(graph_test.adj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indep_vars(n_samples):\n",
    "    \n",
    "    T_list = []\n",
    "    C_list = []\n",
    "    P_list = []\n",
    "    \n",
    "    for i in range(0,n_samples):\n",
    "        \n",
    "        #x = pyro.sample(\"x_{}\".format(i), pyro.distributions.Normal(20,5))\n",
    "        \n",
    "        #T_temp = pyro.distributions.Normal(20,5).sample()\n",
    "        #C_temp = 0.5*pyro.distributions.Beta(1,1+T_temp/10).sample() + 0.5*pyro.distributions.Uniform(0,1).sample()\n",
    "        #P_temp = (0.5*pyro.distributions.Exponential(1).sample() \n",
    "            #+ 0.5*pyro.distributions.Exponential(1/(C_temp+1)).sample())\n",
    "        \n",
    "        T_list.append(pyro.sample(\"T_{}\".format(i), pyro.distributions.Normal(20,5)))\n",
    "        \n",
    "        C_list.append(0.5*pyro.sample(\"C1_{}\".format(i),pyro.distributions.Beta(1,1+T_list[-1]/10)) \n",
    "            + 0.5*pyro.sample(\"C2_{}\".format(i),pyro.distributions.Uniform(0,1)))\n",
    "        P_list.append(0.5*pyro.sample(\"P1_{}\".format(i), pyro.distributions.Exponential(1))\n",
    "            + 0.5*pyro.sample(\"P2.{}\".format(i),pyro.distributions.Exponential(1/(C_list[-1]+1))))\n",
    "        \n",
    "    return T_list,C_list,P_list\n",
    "\n",
    "def dep_vars(T_list,C_list,P_list):\n",
    "    \n",
    "    n_pts = len(T_list)\n",
    "    \n",
    "    I_list = []\n",
    "    \n",
    "    for i in range(0,n_pts):\n",
    "        \n",
    "        T_temp = T_list[i]\n",
    "        C_temp = C_list[i]\n",
    "        P_temp = P_list[i]\n",
    "        \n",
    "        if P_temp > 2.5 or T_temp < 15:\n",
    "            I_list.append(1e-6*pyro.sample(\"I_{}\".format(i),pyro.distributions.Bernoulli(1)))\n",
    "        else:\n",
    "            I_list.append(pyro.sample(\"I_{}\".format(i),\n",
    "                pyro.distributions.Beta(2*(2.5-P_temp)*(T_temp-12)/(2.5*12),2)))\n",
    "            #I_temp = torch.tensor(0.5)\n",
    "        \n",
    "    return I_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data = 10000\n",
    "temp,cloud,precip = indep_vars(n_data)\n",
    "icream = dep_vars(temp,cloud,precip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trinarize data relative to baseline\n",
    "T_base = 20\n",
    "C_base = 0.38\n",
    "P_base = 1.2\n",
    "I_base = 0.23\n",
    "\n",
    "T_sig = 1.0\n",
    "C_sig = 0.02\n",
    "P_sig = 0.06\n",
    "I_sig = 0.01\n",
    "\n",
    "n_count_tri = np.zeros((3,3,3))\n",
    "p_ave_tri = np.zeros((3,3,3,3))\n",
    "\n",
    "def cond_test(val,base,sig):\n",
    "    \n",
    "    conds = [val < base-sig,val > base-sig and val < base+sig,val > base+sig]\n",
    "    \n",
    "    return conds.index(True)-1\n",
    "        \n",
    "T_ind = []\n",
    "C_ind = []\n",
    "P_ind = []\n",
    "I_ind = []\n",
    "for ind in range(0,n_data):\n",
    "    T_ind.append(cond_test(temp[ind],T_base,T_sig))\n",
    "    C_ind.append(cond_test(cloud[ind],C_base,C_sig))\n",
    "    P_ind.append(cond_test(precip[ind],P_base,P_sig))\n",
    "    I_ind.append(cond_test(icream[ind],I_base,I_sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tot_data = np.asarray([T_ind,C_ind,P_ind,I_ind]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(tot_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tot_data[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
