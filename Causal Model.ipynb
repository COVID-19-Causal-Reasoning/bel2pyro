{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.integrate import odeint\n",
    "import networkx as nx\n",
    "\n",
    "import scipy.stats as sp_s\n",
    "\n",
    "import pybel as pb\n",
    "\n",
    "import time\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "\n",
    "pyro.set_rng_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generic discrete probability function\n",
    "class cg_node():\n",
    "    def __init__(self,n_inputs,name):\n",
    "        \n",
    "        self.n_inputs = n_inputs\n",
    "        self.name = name\n",
    "        \n",
    "        if n_inputs == 0:\n",
    "            self.label = 'exogenous'\n",
    "        else:\n",
    "            self.label = 'endogenous'\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def p_init(self,input_data,var_data):\n",
    "        \n",
    "        self.n_data = len(input_data)\n",
    "        \n",
    "        self.input_data = input_data\n",
    "        self.var_data = var_data\n",
    "        \n",
    "        if self.n_inputs == 0:\n",
    "            p_ave = np.zeros(3)\n",
    "            n_count = self.n_data\n",
    "            for i in range(0,3):\n",
    "                p_ave[i] = np.sum(var_data == i-1)/n_count\n",
    "        \n",
    "        elif self.n_inputs == 1:\n",
    "            n_count = np.zeros(3)\n",
    "            p_ave = np.zeros((3,3))\n",
    "            \n",
    "            for i in range(0,3):\n",
    "                n_count[i] = np.sum(input_data == i-1)\n",
    "                for j in range(0,3):\n",
    "                    p_ave[j,i] = np.sum((input_data[:,0] == i-1)*(var_data == j-1))/n_count[i]\n",
    "            \n",
    "            \n",
    "        elif self.n_inputs == 2:\n",
    "            n_count = np.zeros((3,3))\n",
    "            p_ave = np.zeros((3,3,3))\n",
    "            \n",
    "            for i in range(0,3):\n",
    "                for j in range(0,3):\n",
    "                    n_count[i,j] = np.sum((input_data[:,0] == i-1)*(input_data[:,1] == j-1))\n",
    "                    for k in range(0,3):\n",
    "                        p_ave[k,i,j] = np.sum(\n",
    "                            (input_data[:,0] == i-1)*(input_data[:,1] == j-1)*(var_data == k-1))/n_count[i,j]\n",
    "                        \n",
    "        elif self.n_inputs == 3:\n",
    "            n_count = np.zeros((3,3,3))\n",
    "            p_ave = np.zeros((3,3,3,3))\n",
    "            \n",
    "            for i in range(0,3):\n",
    "                for j in range(0,3):\n",
    "                    for k in range(0,3):\n",
    "                        n_count[i,j,k] = np.sum(\n",
    "                            (input_data[:,0] == i-1)*(input_data[:,1] == j-1)*(input_data[:,2] == k-1))\n",
    "                        for m in range(0,3):\n",
    "                            p_ave[m,i,j,k] = np.sum((input_data[:,0] == i-1)*(input_data[:,1] == j-1)\n",
    "                                *(input_data[:,2] == k-1)*(var_data == m-1))/n_count[i,j,k]\n",
    "                            \n",
    "        elif self.n_inputs == 4:\n",
    "            n_count = np.zeros((3,3,3,3))\n",
    "            p_ave = np.zeros((3,3,3,3,3))\n",
    "            \n",
    "            for i in range(0,3):\n",
    "                for j in range(0,3):\n",
    "                    for k in range(0,3):\n",
    "                        for m in range(0,3):\n",
    "                            n_count[i,j,k,m] = np.sum((input_data[:,0] == i-1)*(input_data[:,1] == j-1)\n",
    "                                *(input_data[:,2] == k-1)*(input_data[:,3] == m-1))\n",
    "                            for q in range(0,3):\n",
    "                                p_ave[q,i,j,k,m] = np.sum((input_data[:,0] == i-1)*(input_data[:,1] == j-1)\n",
    "                                    *(input_data[:,2] == k-1)*(input_data[:,3] == m-1)\n",
    "                                    *(var_data == q-1))/n_count[i,j,k,m]\n",
    "                        \n",
    "            \n",
    "        else:\n",
    "            print('error -- too many inputs')\n",
    "            return\n",
    "            \n",
    "        self.n_count = torch.tensor(n_count/self.n_data)\n",
    "        self.prob_dist = torch.tensor(p_ave)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def sample(self,data_in=[]):\n",
    "        \n",
    "        if self.n_inputs == 0:\n",
    "            samp_out = pyro.sample('',pyro.distributions.Multinomial(probs = self.prob_dist)).bool()\n",
    "        elif self.n_inputs == 1:\n",
    "            p_temp = torch.squeeze(self.prob_dist[:,data_in[0]])\n",
    "            samp_out = pyro.sample('',pyro.distributions.Multinomial(probs = p_temp)).bool()\n",
    "        elif self.n_inputs == 2:\n",
    "            p_temp = torch.squeeze(self.prob_dist[:,data_in[0],data_in[1]])\n",
    "            samp_out = pyro.sample('',pyro.distributions.Multinomial(probs = p_temp)).bool()\n",
    "        elif self.n_inputs == 3:\n",
    "            p_temp = torch.squeeze(self.prob_dist[:,data_in[0],data_in[1],data_in[2]])\n",
    "            samp_out = pyro.sample('',pyro.distributions.Multinomial(probs = p_temp)).bool()\n",
    "        else:\n",
    "            print('error -- too many inputs')\n",
    "            samp_out = []\n",
    "        \n",
    "        return samp_out\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cg_graph():\n",
    "    \n",
    "    def __init__(self,str_list=[],bel_graph=[]):\n",
    "        \n",
    "        edge_list = []\n",
    "\n",
    "        entity_list = []\n",
    "        \n",
    "        if str_list:\n",
    "\n",
    "            for item in str_list:\n",
    "\n",
    "                sub_ind = item.find('=')\n",
    "\n",
    "                sub_temp = item[:sub_ind-1]\n",
    "                obj_temp = item[sub_ind+3:]\n",
    "                \n",
    "                rel_temp = item[sub_ind:sub_ind+2]\n",
    "\n",
    "                if sub_temp not in entity_list:\n",
    "                    entity_list.append(sub_temp)\n",
    "                if obj_temp not in entity_list:\n",
    "                    entity_list.append(obj_temp)\n",
    "\n",
    "                edge_list.append([sub_temp,obj_temp,rel_temp])\n",
    "                \n",
    "        elif bel_graph:\n",
    "            \n",
    "            for item in bel_graph.edges:\n",
    "                edge_temp = bel_graph.get_edge_data(item[0],item[1],item[2])\n",
    "                sub_temp = str(item[0])\n",
    "                obj_temp = str(item[1])\n",
    "                rel_temp = edge_temp['relation']\n",
    "                \n",
    "                if sub_temp not in entity_list:\n",
    "                    entity_list.append(sub_temp)\n",
    "                if obj_temp not in entity_list:\n",
    "                    entity_list.append(obj_temp)\n",
    "                \n",
    "                edge_list.append([sub_temp,obj_temp,rel_temp])\n",
    "                \n",
    "\n",
    "        n_nodes = len(entity_list)\n",
    "        self.n_nodes = n_nodes\n",
    "\n",
    "        adj_mat = np.zeros((n_nodes,n_nodes),dtype=int)\n",
    "\n",
    "        for item in edge_list:\n",
    "            out_ind = entity_list.index(item[0])\n",
    "            in_ind = entity_list.index(item[1])\n",
    "            adj_mat[out_ind,in_ind] = 1\n",
    "            \n",
    "        self.edge_list = edge_list\n",
    "        self.entity_list = entity_list\n",
    "        self.adj_mat = adj_mat\n",
    "        \n",
    "        self.graph = nx.DiGraph(adj_mat)\n",
    "        \n",
    "        node_dict = {}\n",
    "        \n",
    "        for i in range(0,n_nodes):\n",
    "            node_dict[entity_list[i]] = cg_node(np.sum(adj_mat[:,i]),entity_list[i])\n",
    "        \n",
    "        self.node_dict = node_dict\n",
    "        \n",
    "        self.cond_list = []\n",
    "        \n",
    "        self.sample_dict = {}\n",
    "        \n",
    "        self.parent_ind_list = []\n",
    "        self.child_ind_list = []\n",
    "        self.parent_name_dict = {}\n",
    "        self.child_name_dict = {}\n",
    "        \n",
    "        self.parent_ind_list = [np.where(self.adj_mat[:,i] > 0)[0] for i in range(0,n_nodes)]\n",
    "        self.child_ind_list = [np.where(self.adj_mat[i,:] > 0)[0] for i in range(0,n_nodes)]\n",
    "        \n",
    "        for i in range(0,n_nodes):\n",
    "            self.parent_name_dict[entity_list[i]] = [entity_list[item] for item in self.parent_ind_list[i]]\n",
    "            self.child_name_dict[entity_list[i]] = [entity_list[item] for item in self.child_ind_list[i]]\n",
    "\n",
    "        # create rank-3 delta tensor\n",
    "        tensor_temp = torch.zeros((3,3,3)).double()\n",
    "        for i in range(0,3):\n",
    "            tensor_temp[i,i,i] = 1\n",
    "            \n",
    "        self.tensor_temp = tensor_temp\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def prob_init(self,data_in):\n",
    "        # initialize all of the nodes\n",
    "        \n",
    "        exog_list = []\n",
    "        prob_dict = {}\n",
    "        \n",
    "        for name in self.node_dict:\n",
    "            i = self.entity_list.index(name)\n",
    "            data_in_temp = data_in[:,self.parent_ind_list[i]]\n",
    "            data_out_temp = data_in[:,i]\n",
    "            \n",
    "            self.node_dict[name].p_init(data_in_temp,data_out_temp)\n",
    "            \n",
    "            if self.node_dict[name].n_inputs == 0:\n",
    "                exog_list.append(name)\n",
    "            prob_dict[name] = self.node_dict[name].prob_dist\n",
    "        \n",
    "        self.exog_list = exog_list\n",
    "        self.prob_dict = prob_dict\n",
    "\n",
    "        return\n",
    "        \n",
    "        \n",
    "    def sample_vars(self,names,flag=0):\n",
    "        # do a multi-variable sample\n",
    "        \n",
    "        # sample only those variables w/o sample data\n",
    "        if np.any([item in self.sample_dict for item in names]):\n",
    "            sample_list = [item for item in names if item not in self.sample_dict]\n",
    "            if sample_list:\n",
    "                self.sample_vars(sample_list,flag+1)\n",
    "        \n",
    "        # sample exogenous variables\n",
    "        elif np.any([item in self.exog_list for item in names]):\n",
    "            in_exog = [item for item in names if item in self.exog_list]\n",
    "            not_in_exog = [item for item in names if item not in self.exog_list]\n",
    "            \n",
    "            for item in in_exog:\n",
    "                self.sample_dict[item] = self.node_dict[item].sample()\n",
    "            if not_in_exog:              \n",
    "                self.sample_vars(not_in_exog,flag+1)\n",
    "            \n",
    "        # if you have samples from all of the parents, sample names\n",
    "        # otherwise, sample the parents\n",
    "        elif names:\n",
    "            \n",
    "            sample_list = []\n",
    "            sample_list2 = []\n",
    "            \n",
    "            for item in names:\n",
    "                parent_list = self.parent_name_dict[item]\n",
    "                \n",
    "                if np.all([item2 in self.sample_dict for item2 in parent_list]):\n",
    "                    self.sample_dict[item] = self.node_dict[item].sample(\n",
    "                        [self.sample_dict[item2] for item2 in parent_list])\n",
    "                else:\n",
    "                    sample_list = sample_list + [item2 for item2 in parent_list if item2 not in sample_list]\n",
    "                    sample_list2 = sample_list2 + [item]\n",
    "            if sample_list:\n",
    "                self.sample_vars(sample_list,flag+1)\n",
    "            if sample_list2:\n",
    "                self.sample_vars(sample_list2,flag+1)\n",
    "            \n",
    "        # if you're back at the root node, return the samples\n",
    "        # otherwise, don't return anything - the values are stored in self.sample_dict\n",
    "        if flag == 0:\n",
    "            \n",
    "            tensor_sample = torch.Tensor([-1,0,1]).int()\n",
    "            \n",
    "            output =[tensor_sample[self.sample_dict[item]] for item in names]\n",
    "            self.sample_dict = {}\n",
    "            return output\n",
    "        else:\n",
    "            return\n",
    "            \n",
    "\n",
    "    def gen_path_nodes(self,sources,destinations):\n",
    "        \n",
    "        source_inds = [self.entity_list.index(item) for item in sources]\n",
    "        dest_inds = [self.entity_list.index(item) for item in destinations]\n",
    "        \n",
    "        nodes = []\n",
    "        \n",
    "        for i in source_inds:\n",
    "            for j in dest_inds:      \n",
    "                for path in nx.all_simple_paths(self.graph, source=i, target=j):\n",
    "                    for ind in path:\n",
    "                        if self.entity_list[ind] not in nodes:\n",
    "                            nodes.append(self.entity_list[ind])\n",
    "                            \n",
    "        return nodes\n",
    "        \n",
    "    \n",
    "    def joint_dist_add(self,add_node,nodes_temp,prob_temp):\n",
    "        # create a new joint distribution with add_node now included\n",
    "        \n",
    "        # deliberately let out 'a' - for the variable being added\n",
    "        str_temp = 'bcdefghijklmnopqrstuvwxyz'\n",
    "        \n",
    "        # find parent indices\n",
    "        par_inds = [nodes_temp.index(item2) for item2 in self.parent_name_dict[add_node]]\n",
    "\n",
    "        n_inds = len(par_inds)\n",
    "\n",
    "        if n_inds == 1:\n",
    "            str1 = 'ay,' + str_temp[par_inds[0]] + 'yz,'\n",
    "            str2 = str_temp[:len(nodes_temp)].replace(str_temp[par_inds[0]],'z')\n",
    "\n",
    "            str_sum = str1 + str2\n",
    "            prob_out = torch.einsum(str_sum,self.prob_dict[add_node],self.tensor_temp,prob_temp)\n",
    "\n",
    "        elif n_inds == 2:                        \n",
    "            str1 = 'awy,' + str_temp[par_inds[0]] + 'wx,' + str_temp[par_inds[1]] + 'yz,'\n",
    "\n",
    "            str2 = str_temp[:len(nodes_temp)].replace(\n",
    "                str_temp[par_inds[0]],'x').replace(str_temp[par_inds[1]],'z')\n",
    "\n",
    "            str_sum = str1 + str2\n",
    "            prob_out = torch.einsum(str_sum,self.prob_dict[add_node],self.tensor_temp,self.tensor_temp,prob_temp)\n",
    "\n",
    "        elif n_inds == 3:\n",
    "            str1 = ('auwy,' + str_temp[par_inds[0]] + 'uv,' + str_temp[par_inds[1]] \n",
    "                    + 'wx,' + str_temp[par_inds[2]] + 'yz,')\n",
    "\n",
    "            str2 = str_temp[:len(nodes_temp)].replace(\n",
    "                str_temp[par_inds[0]],'u').replace(str_temp[par_inds[1]],'x').replace(\n",
    "                str_temp[par_inds[2]],'z')\n",
    "\n",
    "            str_sum = str1 + str2\n",
    "            prob_out = torch.einsum(str_sum,\n",
    "                self.prob_dict[add_node],self.tensor_temp,self.tensor_temp,self.tensor_temp,prob_temp)\n",
    "            \n",
    "        else:\n",
    "            print('too many parents')\n",
    "            prob_out = prob_temp\n",
    "            \n",
    "        return prob_out\n",
    "        \n",
    "    \n",
    "    def calc_prob(self,names):\n",
    "        # calculate the joint probability over a list of named nodes\n",
    "        \n",
    "        # find all paths from exogenous nodes        \n",
    "        path_nodes = self.gen_path_nodes(self.exog_list,names)\n",
    "        \n",
    "        for item in names:\n",
    "            if item in self.exog_list and item not in path_nodes:\n",
    "                path_nodes.append(item)\n",
    "        \n",
    "        print(path_nodes)\n",
    "\n",
    "        # get joint exogenous probability distribution\n",
    "        nodes_temp = []\n",
    "        for item in self.exog_list:\n",
    "            if item in path_nodes:\n",
    "                nodes_temp.append(item)\n",
    "                \n",
    "        #print(nodes_temp)\n",
    "        #print(self.exog_list)\n",
    "        prob_temp = self.prob_dict[nodes_temp[0]]\n",
    "        for item in nodes_temp[1:]:\n",
    "            prob_temp = torch.einsum('...i,j',prob_temp,self.prob_dict[item])\n",
    "        \n",
    "        # identify all of the children of nodes_temp in path_nodes\n",
    "        child_nodes = []\n",
    "        for item in nodes_temp:\n",
    "            for item2 in self.child_name_dict[item]:\n",
    "                if item2 in path_nodes and item2 not in child_nodes:\n",
    "                    child_nodes.append(item2)\n",
    "            \n",
    "        flag = 0\n",
    "        \n",
    "        # iterate through node children until target nodes are reached\n",
    "        while flag == 0:\n",
    "            #print(nodes_temp)\n",
    "            \n",
    "            # determine which nodes to add\n",
    "            # all children of nodes_temp in path_nodes, not in nodes_temp, and that have all their parents in\n",
    "            # nodes_temp\n",
    "            add_nodes = []\n",
    "            for item in nodes_temp:\n",
    "                for item2 in self.child_name_dict[item]:\n",
    "                    if (item2 in path_nodes\n",
    "                        and item2 not in nodes_temp\n",
    "                        and np.all([item3 in nodes_temp for item3 in self.parent_name_dict[item2]])\n",
    "                        and item2 not in add_nodes):\n",
    "                        add_nodes.append(item2)\n",
    "            \n",
    "            #print(add_nodes)\n",
    "\n",
    "            # add nodes to the joint distribution\n",
    "            for item in add_nodes:\n",
    "                prob_temp = self.joint_dist_add(item,nodes_temp,prob_temp)\n",
    "\n",
    "                # add the new node to nodes_temp\n",
    "                nodes_temp = [item] + nodes_temp\n",
    "                \n",
    "            # determine which nodes to subtract\n",
    "            # all nodes in nodes_temp not in names and that have all their children in nodes_temp\n",
    "            sub_nodes = []\n",
    "            for item in nodes_temp:\n",
    "                \n",
    "                child_path_list = []\n",
    "                \n",
    "                for item2 in self.child_name_dict[item]:\n",
    "                    if item2 in path_nodes:\n",
    "                        child_path_list.append(item2)\n",
    "\n",
    "                if item not in names and np.all([item2 in nodes_temp for item2 in child_path_list]):\n",
    "                    sub_nodes.append(item)\n",
    "                    \n",
    "            #print(sub_nodes)\n",
    "                    \n",
    "            # sum over the sub_nodes probabilities\n",
    "            \n",
    "            if sub_nodes:\n",
    "                remove_indices = [nodes_temp.index(item) for item in sub_nodes]\n",
    "                prob_temp = torch.sum(prob_temp,dim=remove_indices)\n",
    "            \n",
    "                # remove summed nodes from nodes_temp\n",
    "                for item in sub_nodes:\n",
    "                    nodes_temp.remove(item)\n",
    "                    \n",
    "            if sorted(nodes_temp) == sorted(names):\n",
    "                flag = 1\n",
    "                permute_inds = [nodes_temp.index(item) for item in names] \n",
    "                prob_temp = prob_temp.permute(permute_inds)\n",
    "\n",
    "            #print()\n",
    "            \n",
    "            \n",
    "        return prob_temp\n",
    "    \n",
    "    \n",
    "    def calc_cond_prob(self,cond_prob,uncond_prob):\n",
    "        \n",
    "        # check to make sure the lists don't overlap\n",
    "        if np.any([item in uncond_prob for item in cond_prob]):\n",
    "            print('error -- overlapping lists')\n",
    "            return\n",
    "        \n",
    "        n_cond = len(cond_prob)\n",
    "        n_uncond = len(cond_prob)\n",
    "        \n",
    "        p_joint = self.calc_prob(cond_prob + uncond_prob)\n",
    "        p_uncond = self.calc_prob(uncond_prob)\n",
    "                \n",
    "        if n_uncond == 1:\n",
    "            p_cond = torch.einsum('...i,ijk,j',p_joint,self.tensor_temp,1/p_uncond)\n",
    "        elif n_uncond == 2:\n",
    "            p_cond = torch.einsum('...il,ijk,lmn,jm',p_joint,self.tensor_temp,self.tensor_temp,1/p_uncond)\n",
    "        elif n_uncond == 3:\n",
    "            p_cond = torch.einsum('...ilp,ijk,lmn,pqr,jmq',\n",
    "                p_joint,self.tensor_temp,self.tensor_temp,self.tensor_temp,1/p_uncond)\n",
    "        else:\n",
    "            print('too many conditioned variables')\n",
    "            p_cond = p_joint\n",
    "            \n",
    "        return p_cond\n",
    "            \n",
    "    \n",
    "    def calc_do(self,names,do_vars,do_vals):\n",
    "        # calculate the final probability distribution of the variable in question given do variables\n",
    "        \n",
    "        # add do_vars to list of exogenous variables\n",
    "        self.exog_list += do_vars\n",
    "        \n",
    "        # sever links from do_vars to parents\n",
    "        child_temp = self.child_name_dict\n",
    "        \n",
    "        for item in self.child_name_dict:\n",
    "            for item2 in do_vars:\n",
    "                if item2 in self.child_name_dict[item]:\n",
    "                    self.child_name_dict[item].remove(item2)\n",
    "        \n",
    "        names_prob_dict = {}\n",
    "        for item in do_vars:\n",
    "            names_prob_dict[item] = self.prob_dict[item]\n",
    "        \n",
    "        # specify distributions for those do_vars\n",
    "        for item in do_vars:\n",
    "            p_temp = np.zeros(3)\n",
    "            p_temp[do_vals[item]+1] = 1\n",
    "            self.prob_dict[item] = torch.Tensor(p_temp)\n",
    "            \n",
    "        \n",
    "        prob_out = self.calc_prob(names)\n",
    "        \n",
    "        # restore original list of exogenous variables\n",
    "        for item in do_vars:\n",
    "            self.exog_list.remove(item)\n",
    "        \n",
    "        # restore original probability distributions\n",
    "        for item in do_vars:\n",
    "            self.prob_dict[item] = names_prob_dict[item]\n",
    "        \n",
    "        # restore original child dictionary\n",
    "        self.child_name_dict = child_temp        \n",
    "        \n",
    "        return prob_out\n",
    "    \n",
    "        \n",
    "    def calc_do_cond(self,do_vars,do_vals,cond_prob,uncond_prob):\n",
    "        \n",
    "        # check to make sure the lists don't overlap\n",
    "        if (np.any([item in uncond_prob for item in cond_prob]) \n",
    "            or np.any([item in do_vars for item in cond_prob])\n",
    "            or np.any([item in do_vars for item in uncond_prob])):\n",
    "            print('error -- overlapping lists')\n",
    "            return\n",
    "        \n",
    "        n_cond = len(cond_prob)\n",
    "        n_uncond = len(cond_prob)\n",
    "            \n",
    "        \n",
    "        p_joint = self.calc_do(cond_prob + uncond_prob,do_vars,do_vals)\n",
    "        p_uncond = self.calc_do(uncond_prob,do_vars,do_vals)\n",
    "                \n",
    "        if n_uncond == 1:\n",
    "            p_cond = torch.einsum('...i,ijk,j',p_joint,self.tensor_temp,1/p_uncond)\n",
    "        elif n_uncond == 2:\n",
    "            p_cond = torch.einsum('...il,ijk,lmn,jm',p_joint,self.tensor_temp,self.tensor_temp,1/p_uncond)\n",
    "        elif n_uncond == 3:\n",
    "            p_cond = torch.einsum('...ilp,ijk,lmn,pqr,jmq',\n",
    "                p_joint,self.tensor_temp,self.tensor_temp,self.tensor_temp,1/p_uncond)\n",
    "        else:\n",
    "            print('too many conditioned variables')\n",
    "            p_cond = p_joint\n",
    "        \n",
    "        return p_cond\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    def calc_counterfact():\n",
    "        return\n",
    "    \n",
    "    def calc_cde(self,names,do_vars,do_vals,ctrl_vars,ctrl_vals):\n",
    "        tot_vars = do_vars + ctrl_vars\n",
    "        tot_vals = {}\n",
    "        tot_ctrl_vals = {}\n",
    "        for item in do_vars:\n",
    "            tot_vals[item] = do_vals[item]\n",
    "            tot_ctrl_vals = ctrl_vals[item]\n",
    "            \n",
    "        for item in ctrl_vars:\n",
    "            tot_vals[item] = 0\n",
    "            tot_ctrl_vals[item] = ctrl_vals[item]\n",
    "            \n",
    "        return self.calc_do(names,tot_vars,tot_vals) - self.calc_do(names,tot_vars,tot_ctrl_vals)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def calc_te(self,names,do_vars,do_vals):\n",
    "        \n",
    "        do_vals_0 = {}\n",
    "        for item in do_vals:\n",
    "            do_vals_0[item] = 0\n",
    "            \n",
    "        return self.calc_do(names,do_vars,do_vals) - self.calc_do(do_vars,do_vals_0)\n",
    "    \n",
    "    def calc_nde(self,names,do_vars,do_vals):\n",
    "        \n",
    "        # identify parents of names\n",
    "        parent_list = []\n",
    "        for item in names:\n",
    "            for item2 in self.parent_name_dict[item]:\n",
    "                if item2 not in parent_list:\n",
    "                    parent_list.append(item2)\n",
    "                    \n",
    "        par_do_vals = []\n",
    "        for item in do_vars:\n",
    "            if item in parent_list:\n",
    "                par_do_vals.append(item)\n",
    "        \n",
    "        if not par_do_vals:\n",
    "            print('no direct effect')\n",
    "            prob_out = 0\n",
    "        \n",
    "        else:\n",
    "            # calculate probability of non-do_var parents given do_vars = 0\n",
    "            \n",
    "            non_do_parents = [item for item in parent_list if item not in do_vars]\n",
    "            do_vals_0 = {}\n",
    "            for item in do_vars:\n",
    "                do_vals_0[item] = 0\n",
    "            \n",
    "            non_par_do_vars = []\n",
    "            for item in do_vars:\n",
    "                if item not in parent_list:\n",
    "                    non_par_do_vars.append(item)\n",
    "            \n",
    "            nodes_temp = non_do_parents\n",
    "            \n",
    "            prob_temp = self.calc_do(non_do_parents,do_vars,do_vals_0)\n",
    "            # do outer product to get overall distribution\n",
    "            for item in non_par_do_vars:\n",
    "                p_temp = np.zeros(3)\n",
    "                p_temp[do_vals[item]] = 1\n",
    "                p_add = torch.Tensor(p_temp)\n",
    "                prob_temp = torch.einsum('...i,j',prob_temp,p_add)\n",
    "                nodes_temp.append(item)\n",
    "            \n",
    "            n_sum = len(nodes_temp)\n",
    "            n_names = len(names)\n",
    "            for item in names:\n",
    "                prob_temp = self.joint_dist_add(item,nodes_temp,prob_temp)\n",
    "                \n",
    "            # calculate overall joint probability distribution\n",
    "            sum_axes = range(n_names,n_names+n_sum)\n",
    "            prob_do_vals = np.sum(prob_temp,axis=tuple(sum_axes))\n",
    "            \n",
    "            prob_out = prob_do_vals - self.calc_do(names,do_vars,do_vals_0)\n",
    "\n",
    "        return prob_out\n",
    "    \n",
    "    def calc_nie():\n",
    "        # identify parents of names\n",
    "        parent_list = []\n",
    "        for item in names:\n",
    "            for item2 in self.parent_name_dict[item]:\n",
    "                if item2 not in parent_list:\n",
    "                    parent_list.append(item2)\n",
    "                    \n",
    "        par_do_vals = []\n",
    "        for item in parent_list:\n",
    "            if item in do_vars:\n",
    "                par_do_vals.append(item)\n",
    "        \n",
    "        if np.all([item in do_vars for item in parent_list]):\n",
    "            print('no indirect effect')\n",
    "            prob_out = 0\n",
    "        \n",
    "        else:\n",
    "            # calculate probability of non-do_var parents given do_vars = do_vals\n",
    "            \n",
    "            non_do_parents = [item for item in parent_list if item not in do_vars]\n",
    "            do_vals_0 = {}\n",
    "            for item in do_vars:\n",
    "                do_vals_0[item] = 0\n",
    "            \n",
    "            non_par_do_vars = []\n",
    "            for item in do_vars:\n",
    "                if item not in parent_list:\n",
    "                    non_par_do_vars.append(item)\n",
    "            \n",
    "            nodes_temp = non_do_parents\n",
    "            \n",
    "            prob_temp = self.calc_do(non_do_parents,do_vars,do_vals)\n",
    "            # do outer product to get overall distribution\n",
    "            for item in non_par_do_vars:\n",
    "                p_temp = np.zeros(3)\n",
    "                p_temp[1] = 1\n",
    "                p_add = torch.Tensor(p_temp)\n",
    "                prob_temp = torch.einsum('...i,j',prob_temp,p_add)\n",
    "                nodes_temp.append(item)\n",
    "            \n",
    "            n_sum = len(nodes_temp)\n",
    "            n_names = len(names)\n",
    "            for item in names:\n",
    "                prob_temp = self.joint_dist_add(item,nodes_temp,prob_temp)\n",
    "                \n",
    "            # calculate overall joint probability distribution\n",
    "            sum_axes = range(n_names,n_names+n_sum)\n",
    "            prob_do_vals = np.sum(prob_temp,axis=tuple(sum_axes))\n",
    "            \n",
    "            prob_out = prob_do_vals - self.calc_do(names,do_vars,do_vals_0)\n",
    "\n",
    "        return prob_out\n",
    "\n",
    "    def cond_mut_info(self,target,test,cond,data_in):\n",
    "        \n",
    "        cond_temp = cond\n",
    "        \n",
    "        if not cond:\n",
    "            # find parents of target\n",
    "            for item in target:\n",
    "                for item2 in self.parent_name_dict[item]:\n",
    "                    if item2 not in cond_temp:\n",
    "                        cond_temp.append(item2)\n",
    "        \n",
    "        \n",
    "        target_inds = [self.entity_list.index(item) for item in target]\n",
    "        test_inds = [self.entity_list.index(item) for item in test]\n",
    "        cond_inds = [self.entity_list.index(item) for item in cond_temp]\n",
    "        \n",
    "        n_total = len(data_in)\n",
    "        \n",
    "        null_joint = data_in[:,target_inds + cond_inds]\n",
    "        null_cond = data_in[:,cond_inds]\n",
    "        \n",
    "        hypth_joint = data_in[:,target_inds + test_inds + cond_inds]\n",
    "        hypth_cond = data_in[:,test_inds + cond_inds]\n",
    "        \n",
    "        null_entropy = 0\n",
    "        null_list = []\n",
    "        \n",
    "        hypth_entropy = 0\n",
    "        hypth_list = []\n",
    "        for i in range(0,n_total):\n",
    "\n",
    "            if np.all([np.any(null_joint[i,:] != item) for item in null_list]):\n",
    "                num_sum = np.sum([np.all(null_joint[i,:] == item) for item in null_joint])\n",
    "                denom_sum = np.sum([np.all(null_cond[i,:] == item) for item in null_cond])\n",
    "                null_entropy = null_entropy - num_sum*np.log(num_sum/denom_sum)\n",
    "                null_list.append(null_joint[i,:])\n",
    "            \n",
    "            if np.all([np.any(hypth_joint[i,:] != item) for item in hypth_list]):\n",
    "                num_sum = np.sum([np.all(hypth_joint[i,:] == item) for item in hypth_joint])\n",
    "                denom_sum = np.sum([np.all(hypth_cond[i,:] == item) for item in hypth_cond])\n",
    "                hypth_entropy = hypth_entropy - num_sum*np.log(num_sum/denom_sum)\n",
    "                hypth_list.append(hypth_joint[i,:])\n",
    "                \n",
    "        return (null_entropy - hypth_entropy)/n_total\n",
    "        \n",
    "    def g_test(self,name,data_in):\n",
    "        # do the G-test on a single variable of interest\n",
    "        \n",
    "        p_name = self.calc_prob(name)*len(data_in)\n",
    "        name_ind = self.entity_list.index(name[0])\n",
    "        name_data = data_in[:,name_ind]\n",
    "        \n",
    "        p_data = torch.Tensor([np.sum(name_data == -1),np.sum(name_data == 0),np.sum(name_data == 1)])\n",
    "        \n",
    "        print(p_name)\n",
    "        print(p_data)\n",
    "        \n",
    "        g_val = 2*torch.sum(p_data*torch.log(p_data/p_name))\n",
    "        \n",
    "        dof = len(data_in) - 1\n",
    "        \n",
    "        p_val = 1-sp.stats.chi2.cdf(g_val.item(), dof)\n",
    "        \n",
    "        return g_val,p_val\n",
    "    \n",
    "    def g_test_emp(self,name,data_in):\n",
    "        # do the G-test on a single variable of interest\n",
    "        \n",
    "        #p_name = self.calc_prob(name)*len(data_in)\n",
    "        # generate an empirical distribution for variable name\n",
    "        model_data = np.zeros(len(data_in))\n",
    "        for i in range(0,len(data_in)):\n",
    "            model_data[i] = self.sample_vars(name)[0].item()\n",
    "            \n",
    "        p_model = torch.Tensor([np.sum(model_data == -1),np.sum(model_data == 0),np.sum(model_data == 1)])\n",
    "        print(p_model)\n",
    "        \n",
    "        name_ind = self.entity_list.index(name[0])\n",
    "        name_data = data_in[:,name_ind]\n",
    "        \n",
    "        p_data = torch.Tensor([np.sum(name_data == -1),np.sum(name_data == 0),np.sum(name_data == 1)])\n",
    "        print(p_data)\n",
    "        \n",
    "        g_val = 2*torch.sum(p_data*torch.log(p_data/p_model))\n",
    "        \n",
    "        dof = len(data_in) - 1\n",
    "        \n",
    "        p_val = 1-sp.stats.chi2.cdf(g_val.item(), dof)\n",
    "        \n",
    "        return g_val,p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bel_temp = pb.from_bel_script('temp.txt')\n",
    "graph_test = cg_graph(bel_graph=bel_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(dir(graph_test))\n",
    "print()\n",
    "for item in graph_test.edge_list:\n",
    "    print(item)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_list = ['temp =| cloudy','cloudy => rainy','temp => icream','rainy =| icream']\n",
    "graph_test = cg_graph(str_list=str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp', 0]\n",
      "['cloudy', 1]\n",
      "['rainy', 1]\n",
      "['icream', 2]\n"
     ]
    }
   ],
   "source": [
    "for item in graph_test.node_dict:\n",
    "    print([graph_test.node_dict[item].name,graph_test.node_dict[item].n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp']\n"
     ]
    }
   ],
   "source": [
    "graph_test.prob_init(tot_data)\n",
    "print(graph_test.exog_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for item in graph_test.node_dict:\n",
    "    print(item)\n",
    "    print(graph_test.node_dict[item].n_count)\n",
    "    print(graph_test.node_dict[item].prob_dist)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_test.sample_vars(['icream','rainy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = graph_test.calc_prob(['rainy','icream'])\n",
    "y = graph_test.calc_prob(['icream'])\n",
    "y2 = graph_test.calc_prob(['rainy'])\n",
    "print(x)\n",
    "print()\n",
    "print(y)\n",
    "print(torch.sum(x,dim=0))\n",
    "\n",
    "print()\n",
    "print(y2)\n",
    "print(torch.sum(x,dim=1))\n",
    "\n",
    "# this is somehow reversed!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = graph_test.calc_cond_prob(['rainy'],['icream'])\n",
    "print()\n",
    "print(z)\n",
    "print()\n",
    "print(torch.matmul(z,y))\n",
    "\n",
    "print(torch.sum(z,dim=1))\n",
    "\n",
    "print(torch.sum(z,dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do_dict = {}\n",
    "do_dict['rainy'] = torch.Tensor([1]).int()\n",
    "for item in do_dict:\n",
    "    print(do_dict[item])\n",
    "    print(graph_test.prob_dict[item])\n",
    "\n",
    "\n",
    "print(graph_test.exog_list)\n",
    "a1 = graph_test.calc_do(['icream'],['rainy'],do_dict)\n",
    "print(a1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_test.calc_do_cond(['rainy'],do_dict,['temp'],['icream'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in graph_test.prob_dict:\n",
    "    print(item)\n",
    "    print(graph_test.prob_dict[item])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06246318178181064\n"
     ]
    }
   ],
   "source": [
    "print(graph_test.cond_mut_info(['icream'],['rainy'],['temp'],tot_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(graph_test.gen_path_nodes(graph_test.exog_list,['temp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4295, 0.1507, 0.4198], dtype=torch.float64)\n",
      "['temp']\n",
      "tensor([4295., 1507., 4198.], dtype=torch.float64)\n",
      "tensor([4295., 1507., 4198.])\n",
      "(tensor(0., dtype=torch.float64), 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(graph_test.prob_dict['temp'])\n",
    "\n",
    "a = graph_test.g_test(['temp'],tot_data)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4539],\n",
      "        [0.0883],\n",
      "        [0.4579]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(graph_test.prob_dict['cloudy'][:,graph_test.node_dict['temp'].sample()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4189, 0.4539, 0.4962],\n",
      "        [0.0761, 0.0883, 0.0707],\n",
      "        [0.5050, 0.4579, 0.4331]], dtype=torch.float64)\n",
      "['temp', 'cloudy']\n",
      "tensor([0.4566, 0.0757, 0.4677], dtype=torch.float64)\n",
      "tensor([0.4566, 0.0757, 0.4677], dtype=torch.float64)\n",
      "tensor([0.4034, 0.4005, 0.4056], dtype=torch.float64)\n",
      "\n",
      "tensor([6015.,  188., 3797.])\n",
      "tensor([5946.,  196., 3858.])\n",
      "(tensor(2.1053), 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(graph_test.prob_dict['cloudy'])\n",
    "print(graph_test.calc_prob(['cloudy']))\n",
    "print(torch.matmul(graph_test.prob_dict['cloudy'],graph_test.prob_dict['temp']))\n",
    "print(torch.matmul(graph_test.prob_dict['temp'],graph_test.prob_dict['cloudy']))\n",
    "print()\n",
    "\n",
    "a = graph_test.g_test_emp(['icream'],tot_data)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = pyro.sample('',pyro.distributions.Multinomial(probs = torch.Tensor([0.3,0.2,0.5]))).bool()\n",
    "#samp_out = pyro.sample('',pyro.distributions.Multinomial(probs = self.prob_dist))\n",
    "print(x)\n",
    "y = torch.Tensor([-1,0,1])[x]\n",
    "print(y)\n",
    "\n",
    "z = torch.Tensor([1]).int()\n",
    "print(z)\n",
    "print(z+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(graph_test.calc_prob(['icream']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(dir(graph_test))\n",
    "print()\n",
    "print(graph_test.entity_list)\n",
    "print(graph_test.adj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indep_vars(n_samples):\n",
    "    \n",
    "    T_list = []\n",
    "    C_list = []\n",
    "    P_list = []\n",
    "    \n",
    "    for i in range(0,n_samples):\n",
    "        \n",
    "        #x = pyro.sample(\"x_{}\".format(i), pyro.distributions.Normal(20,5))\n",
    "        \n",
    "        #T_temp = pyro.distributions.Normal(20,5).sample()\n",
    "        #C_temp = 0.5*pyro.distributions.Beta(1,1+T_temp/10).sample() + 0.5*pyro.distributions.Uniform(0,1).sample()\n",
    "        #P_temp = (0.5*pyro.distributions.Exponential(1).sample() \n",
    "            #+ 0.5*pyro.distributions.Exponential(1/(C_temp+1)).sample())\n",
    "        \n",
    "        T_list.append(pyro.sample(\"T_{}\".format(i), pyro.distributions.Normal(20,5)))\n",
    "        \n",
    "        C_list.append(0.5*pyro.sample(\"C1_{}\".format(i),pyro.distributions.Beta(1,1+T_list[-1]/10)) \n",
    "            + 0.5*pyro.sample(\"C2_{}\".format(i),pyro.distributions.Uniform(0,1)))\n",
    "        P_list.append(0.5*pyro.sample(\"P1_{}\".format(i), pyro.distributions.Exponential(1))\n",
    "            + 0.5*pyro.sample(\"P2.{}\".format(i),pyro.distributions.Exponential(1/(C_list[-1]+1))))\n",
    "        \n",
    "    return T_list,C_list,P_list\n",
    "\n",
    "def dep_vars(T_list,C_list,P_list):\n",
    "    \n",
    "    n_pts = len(T_list)\n",
    "    \n",
    "    I_list = []\n",
    "    \n",
    "    for i in range(0,n_pts):\n",
    "        \n",
    "        T_temp = T_list[i]\n",
    "        C_temp = C_list[i]\n",
    "        P_temp = P_list[i]\n",
    "        \n",
    "        if P_temp > 2.5 or T_temp < 15:\n",
    "            I_list.append(1e-6*pyro.sample(\"I_{}\".format(i),pyro.distributions.Bernoulli(1)))\n",
    "        else:\n",
    "            I_list.append(pyro.sample(\"I_{}\".format(i),\n",
    "                pyro.distributions.Beta(2*(2.5-P_temp)*(T_temp-12)/(2.5*12),2)))\n",
    "            #I_temp = torch.tensor(0.5)\n",
    "        \n",
    "    return I_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_data = 10000\n",
    "temp,cloud,precip = indep_vars(n_data)\n",
    "icream = dep_vars(temp,cloud,precip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trinarize data relative to baseline\n",
    "T_base = 20\n",
    "C_base = 0.38\n",
    "P_base = 1.2\n",
    "I_base = 0.23\n",
    "\n",
    "T_sig = 1.0\n",
    "C_sig = 0.02\n",
    "P_sig = 0.06\n",
    "I_sig = 0.01\n",
    "\n",
    "n_count_tri = np.zeros((3,3,3))\n",
    "p_ave_tri = np.zeros((3,3,3,3))\n",
    "\n",
    "def cond_test(val,base,sig):\n",
    "    \n",
    "    conds = [val < base-sig,val > base-sig and val < base+sig,val > base+sig]\n",
    "    \n",
    "    return conds.index(True)-1\n",
    "        \n",
    "T_ind = []\n",
    "C_ind = []\n",
    "P_ind = []\n",
    "I_ind = []\n",
    "for ind in range(0,n_data):\n",
    "    T_ind.append(cond_test(temp[ind],T_base,T_sig))\n",
    "    C_ind.append(cond_test(cloud[ind],C_base,C_sig))\n",
    "    P_ind.append(cond_test(precip[ind],P_base,P_sig))\n",
    "    I_ind.append(cond_test(icream[ind],I_base,I_sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tot_data = np.asarray([T_ind,C_ind,P_ind,I_ind]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(tot_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tot_data[0:5,:])\n",
    "print(type(tot_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
